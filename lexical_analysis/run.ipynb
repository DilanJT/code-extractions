{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match if\n",
      "tokens after checking reserved words \n",
      " ['IF']\n",
      "tokens after checking identifiers words \n",
      " ['IF']\n",
      "Invalid input at position 0\n",
      "tokens after checking reserved words \n",
      " ['IF']\n",
      "match <re.Match object; span=(0, 1), match='f'>\n",
      "tokens after checking identifiers words \n",
      " ['IF', 'IDENTIFIER:f']\n",
      "tokens after checking reserved words \n",
      " ['IF', 'IDENTIFIER:f']\n",
      "match None\n",
      "tokens after checking identifiers words \n",
      " ['IF', 'IDENTIFIER:f']\n",
      "Invalid input at position 2\n",
      "tokens after checking reserved words \n",
      " ['IF', 'IDENTIFIER:f']\n",
      "match <re.Match object; span=(0, 1), match='x'>\n",
      "tokens after checking identifiers words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x']\n",
      "tokens after checking reserved words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x']\n",
      "match None\n",
      "tokens after checking identifiers words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x']\n",
      "Invalid input at position 4\n",
      "tokens after checking reserved words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x']\n",
      "match None\n",
      "tokens after checking identifiers words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x']\n",
      "Invalid input at position 5\n",
      "tokens after checking reserved words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x']\n",
      "match None\n",
      "tokens after checking identifiers words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x']\n",
      "Invalid input at position 6\n",
      "tokens after checking reserved words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x']\n",
      "match None\n",
      "tokens after checking identifiers words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x']\n",
      "Invalid input at position 7\n",
      "tokens after checking reserved words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x']\n",
      "match None\n",
      "tokens after checking identifiers words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x']\n",
      "Invalid input at position 8\n",
      "tokens after checking reserved words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x']\n",
      "match None\n",
      "tokens after checking identifiers words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x']\n",
      "Invalid input at position 9\n",
      "tokens after checking reserved words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x']\n",
      "match None\n",
      "tokens after checking identifiers words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x']\n",
      "Invalid input at position 10\n",
      "tokens after checking reserved words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x']\n",
      "match None\n",
      "tokens after checking identifiers words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x']\n",
      "Invalid input at position 11\n",
      "tokens after checking reserved words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x']\n",
      "match None\n",
      "tokens after checking identifiers words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x']\n",
      "Invalid input at position 12\n",
      "tokens after checking reserved words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x']\n",
      "match None\n",
      "tokens after checking identifiers words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x']\n",
      "Invalid input at position 13\n",
      "match print\n",
      "tokens after checking reserved words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT']\n",
      "tokens after checking identifiers words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT']\n",
      "Invalid input at position 14\n",
      "tokens after checking reserved words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT']\n",
      "match <re.Match object; span=(0, 4), match='rint'>\n",
      "tokens after checking identifiers words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint']\n",
      "tokens after checking reserved words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint']\n",
      "match None\n",
      "tokens after checking identifiers words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint']\n",
      "Invalid input at position 19\n",
      "tokens after checking reserved words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint']\n",
      "match None\n",
      "tokens after checking identifiers words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint']\n",
      "Invalid input at position 20\n",
      "tokens after checking reserved words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint']\n",
      "match <re.Match object; span=(0, 1), match='x'>\n",
      "tokens after checking identifiers words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x']\n",
      "tokens after checking reserved words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x']\n",
      "match None\n",
      "tokens after checking identifiers words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x']\n",
      "Invalid input at position 22\n",
      "tokens after checking reserved words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x']\n",
      "match <re.Match object; span=(0, 2), match='is'>\n",
      "tokens after checking identifiers words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is']\n",
      "tokens after checking reserved words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is']\n",
      "match None\n",
      "tokens after checking identifiers words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is']\n",
      "Invalid input at position 25\n",
      "tokens after checking reserved words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is']\n",
      "match <re.Match object; span=(0, 8), match='positive'>\n",
      "tokens after checking identifiers words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:positive']\n",
      "tokens after checking reserved words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:positive']\n",
      "match None\n",
      "tokens after checking identifiers words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:positive']\n",
      "Invalid input at position 34\n",
      "tokens after checking reserved words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:positive']\n",
      "match None\n",
      "tokens after checking identifiers words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:positive']\n",
      "Invalid input at position 35\n",
      "tokens after checking reserved words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:positive']\n",
      "match None\n",
      "tokens after checking identifiers words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:positive']\n",
      "Invalid input at position 36\n",
      "match else\n",
      "tokens after checking reserved words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:positive', 'ELSE']\n",
      "tokens after checking identifiers words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:positive', 'ELSE']\n",
      "Invalid input at position 37\n",
      "tokens after checking reserved words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:positive', 'ELSE']\n",
      "match <re.Match object; span=(0, 3), match='lse'>\n",
      "tokens after checking identifiers words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:positive', 'ELSE', 'IDENTIFIER:lse']\n",
      "tokens after checking reserved words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:positive', 'ELSE', 'IDENTIFIER:lse']\n",
      "match None\n",
      "tokens after checking identifiers words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:positive', 'ELSE', 'IDENTIFIER:lse']\n",
      "Invalid input at position 41\n",
      "tokens after checking reserved words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:positive', 'ELSE', 'IDENTIFIER:lse']\n",
      "match None\n",
      "tokens after checking identifiers words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:positive', 'ELSE', 'IDENTIFIER:lse']\n",
      "Invalid input at position 42\n",
      "tokens after checking reserved words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:positive', 'ELSE', 'IDENTIFIER:lse']\n",
      "match None\n",
      "tokens after checking identifiers words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:positive', 'ELSE', 'IDENTIFIER:lse']\n",
      "Invalid input at position 43\n",
      "tokens after checking reserved words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:positive', 'ELSE', 'IDENTIFIER:lse']\n",
      "match None\n",
      "tokens after checking identifiers words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:positive', 'ELSE', 'IDENTIFIER:lse']\n",
      "Invalid input at position 44\n",
      "tokens after checking reserved words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:positive', 'ELSE', 'IDENTIFIER:lse']\n",
      "match None\n",
      "tokens after checking identifiers words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:positive', 'ELSE', 'IDENTIFIER:lse']\n",
      "Invalid input at position 45\n",
      "tokens after checking reserved words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:positive', 'ELSE', 'IDENTIFIER:lse']\n",
      "match None\n",
      "tokens after checking identifiers words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:positive', 'ELSE', 'IDENTIFIER:lse']\n",
      "Invalid input at position 46\n",
      "match print\n",
      "tokens after checking reserved words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:positive', 'ELSE', 'IDENTIFIER:lse', 'PRINT']\n",
      "tokens after checking identifiers words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:positive', 'ELSE', 'IDENTIFIER:lse', 'PRINT']\n",
      "Invalid input at position 47\n",
      "tokens after checking reserved words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:positive', 'ELSE', 'IDENTIFIER:lse', 'PRINT']\n",
      "match <re.Match object; span=(0, 4), match='rint'>\n",
      "tokens after checking identifiers words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:positive', 'ELSE', 'IDENTIFIER:lse', 'PRINT', 'IDENTIFIER:rint']\n",
      "tokens after checking reserved words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:positive', 'ELSE', 'IDENTIFIER:lse', 'PRINT', 'IDENTIFIER:rint']\n",
      "match None\n",
      "tokens after checking identifiers words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:positive', 'ELSE', 'IDENTIFIER:lse', 'PRINT', 'IDENTIFIER:rint']\n",
      "Invalid input at position 52\n",
      "tokens after checking reserved words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:positive', 'ELSE', 'IDENTIFIER:lse', 'PRINT', 'IDENTIFIER:rint']\n",
      "match None\n",
      "tokens after checking identifiers words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:positive', 'ELSE', 'IDENTIFIER:lse', 'PRINT', 'IDENTIFIER:rint']\n",
      "Invalid input at position 53\n",
      "tokens after checking reserved words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:positive', 'ELSE', 'IDENTIFIER:lse', 'PRINT', 'IDENTIFIER:rint']\n",
      "match <re.Match object; span=(0, 1), match='x'>\n",
      "tokens after checking identifiers words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:positive', 'ELSE', 'IDENTIFIER:lse', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x']\n",
      "tokens after checking reserved words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:positive', 'ELSE', 'IDENTIFIER:lse', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x']\n",
      "match None\n",
      "tokens after checking identifiers words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:positive', 'ELSE', 'IDENTIFIER:lse', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x']\n",
      "Invalid input at position 55\n",
      "tokens after checking reserved words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:positive', 'ELSE', 'IDENTIFIER:lse', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x']\n",
      "match <re.Match object; span=(0, 2), match='is'>\n",
      "tokens after checking identifiers words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:positive', 'ELSE', 'IDENTIFIER:lse', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is']\n",
      "tokens after checking reserved words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:positive', 'ELSE', 'IDENTIFIER:lse', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is']\n",
      "match None\n",
      "tokens after checking identifiers words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:positive', 'ELSE', 'IDENTIFIER:lse', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is']\n",
      "Invalid input at position 58\n",
      "tokens after checking reserved words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:positive', 'ELSE', 'IDENTIFIER:lse', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is']\n",
      "match <re.Match object; span=(0, 3), match='non'>\n",
      "tokens after checking identifiers words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:positive', 'ELSE', 'IDENTIFIER:lse', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:non']\n",
      "tokens after checking reserved words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:positive', 'ELSE', 'IDENTIFIER:lse', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:non']\n",
      "match None\n",
      "tokens after checking identifiers words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:positive', 'ELSE', 'IDENTIFIER:lse', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:non']\n",
      "Invalid input at position 62\n",
      "tokens after checking reserved words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:positive', 'ELSE', 'IDENTIFIER:lse', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:non']\n",
      "match <re.Match object; span=(0, 8), match='positive'>\n",
      "tokens after checking identifiers words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:positive', 'ELSE', 'IDENTIFIER:lse', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:non', 'IDENTIFIER:positive']\n",
      "tokens after checking reserved words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:positive', 'ELSE', 'IDENTIFIER:lse', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:non', 'IDENTIFIER:positive']\n",
      "match None\n",
      "tokens after checking identifiers words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:positive', 'ELSE', 'IDENTIFIER:lse', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:non', 'IDENTIFIER:positive']\n",
      "Invalid input at position 71\n",
      "tokens after checking reserved words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:positive', 'ELSE', 'IDENTIFIER:lse', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:non', 'IDENTIFIER:positive']\n",
      "match None\n",
      "tokens after checking identifiers words \n",
      " ['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:positive', 'ELSE', 'IDENTIFIER:lse', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:non', 'IDENTIFIER:positive']\n",
      "Invalid input at position 72\n",
      "['IF', 'IDENTIFIER:f', 'IDENTIFIER:x', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:positive', 'ELSE', 'IDENTIFIER:lse', 'PRINT', 'IDENTIFIER:rint', 'IDENTIFIER:x', 'IDENTIFIER:is', 'IDENTIFIER:non', 'IDENTIFIER:positive']\n"
     ]
    }
   ],
   "source": [
    "from lexemes import tokenize\n",
    "\n",
    "input_string = 'if x > 0:\\n    print(\"x is positive\")\\nelse:\\n    print(\"x is non-positive\")'\n",
    "\n",
    "tokens = tokenize(input_string)\n",
    "\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifiers: ['def', 'add_numbers', 'a', 'b', 'result', 'a', 'b', 'return', 'result', 'x', 'y', 'z', 'add_numbers', 'x', 'y', 'print', 'z']\n",
      "Reserved words: ['def', 'return', 'print']\n"
     ]
    }
   ],
   "source": [
    "from extract_reserved_identifiers import identifier_extractor, reserved_word_extractor\n",
    "\n",
    "code_snippet = '''\n",
    "def add_numbers(a, b):\n",
    "    result = a + b\n",
    "    return result\n",
    "\n",
    "x = 5\n",
    "y = 10\n",
    "z = add_numbers(x, y)\n",
    "print(z)\n",
    "'''\n",
    "\n",
    "identifiers = identifier_extractor(code_snippet)\n",
    "reserved_words = reserved_word_extractor(code_snippet)\n",
    "\n",
    "print(\"Identifiers:\", identifiers)\n",
    "print(\"Reserved words:\", reserved_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "not enough arguments for format string",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\dilan_files\\FYP_code\\code_extractions\\lexical_analysis\\run.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/dilan_files/FYP_code/code_extractions/lexical_analysis/run.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mreg_tokenizer\u001b[39;00m \u001b[39mimport\u001b[39;00m extract_tokens_pairs\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/dilan_files/FYP_code/code_extractions/lexical_analysis/run.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m input_code \u001b[39m=\u001b[39m \u001b[39m'''\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/dilan_files/FYP_code/code_extractions/lexical_analysis/run.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mdef add_numbers(a, b):\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/dilan_files/FYP_code/code_extractions/lexical_analysis/run.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m    result = a + b\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/dilan_files/FYP_code/code_extractions/lexical_analysis/run.ipynb#W2sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint(z)\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/dilan_files/FYP_code/code_extractions/lexical_analysis/run.ipynb#W2sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m'''\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/dilan_files/FYP_code/code_extractions/lexical_analysis/run.ipynb#W2sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m tokens \u001b[39m=\u001b[39m extract_tokens_pairs(input_code)\n",
      "File \u001b[1;32md:\\dilan_files\\FYP_code\\code_extractions\\lexical_analysis\\reg_tokenizer.py:55\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     51\u001b[0m     tokens \u001b[39m=\u001b[39m [token \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m tokens \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m token\u001b[39m.\u001b[39misspace()]\n\u001b[0;32m     53\u001b[0m     \u001b[39mreturn\u001b[39;00m tokens\n\u001b[1;32m---> 55\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m, extract_tokens_pairs(\u001b[39m\"\u001b[39;49m\u001b[39mprint(\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mHello World!\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m)\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "File \u001b[1;32md:\\dilan_files\\FYP_code\\code_extractions\\lexical_analysis\\reg_tokenizer.py:19\u001b[0m, in \u001b[0;36mextract_tokens_pairs\u001b[1;34m(input_code)\u001b[0m\n\u001b[0;32m      7\u001b[0m token_patterns \u001b[39m=\u001b[39m {\n\u001b[0;32m      8\u001b[0m     \u001b[39m'\u001b[39m\u001b[39midentifier\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m[a-zA-Z_][a-zA-Z0-9_]*\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      9\u001b[0m     \u001b[39m'\u001b[39m\u001b[39minteger_literal\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md+\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mreserved_word\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mb(and|as|assert|async|await|break|class|continue|def|del|elif|else|except|False|finally|for|from|global|if|import|in|is|lambda|None|nonlocal|not|or|pass|raise|return|True|try|while|with|yield|print)\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     15\u001b[0m }\n\u001b[0;32m     17\u001b[0m \u001b[39m# Combine all patterns into a single regex pattern\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39m#regex_pattern = '|'.join('(?P<%s>%s)' % pair for pair in zip(token_patterns[0::2], token_patterns[1::2]))\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m regex_pattern \u001b[39m=\u001b[39m \u001b[39m'\u001b[39;49m\u001b[39m|\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(\u001b[39m'\u001b[39;49m\u001b[39m(?P<\u001b[39;49m\u001b[39m%s\u001b[39;49;00m\u001b[39m>\u001b[39;49m\u001b[39m%s\u001b[39;49;00m\u001b[39m)\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39m%\u001b[39;49m pair \u001b[39mfor\u001b[39;49;00m pair \u001b[39min\u001b[39;49;00m token_patterns)\n\u001b[0;32m     20\u001b[0m \u001b[39m#print(\"regex_pattern\", regex_pattern)\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \n\u001b[0;32m     22\u001b[0m \u001b[39m# Tokenize the input string using the regex pattern\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[39m# Tokenize the input string using the regex pattern\u001b[39;00m\n\u001b[0;32m     24\u001b[0m tokens \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32md:\\dilan_files\\FYP_code\\code_extractions\\lexical_analysis\\reg_tokenizer.py:19\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      7\u001b[0m token_patterns \u001b[39m=\u001b[39m {\n\u001b[0;32m      8\u001b[0m     \u001b[39m'\u001b[39m\u001b[39midentifier\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m[a-zA-Z_][a-zA-Z0-9_]*\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      9\u001b[0m     \u001b[39m'\u001b[39m\u001b[39minteger_literal\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md+\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mreserved_word\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mb(and|as|assert|async|await|break|class|continue|def|del|elif|else|except|False|finally|for|from|global|if|import|in|is|lambda|None|nonlocal|not|or|pass|raise|return|True|try|while|with|yield|print)\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     15\u001b[0m }\n\u001b[0;32m     17\u001b[0m \u001b[39m# Combine all patterns into a single regex pattern\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39m#regex_pattern = '|'.join('(?P<%s>%s)' % pair for pair in zip(token_patterns[0::2], token_patterns[1::2]))\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m regex_pattern \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m|\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39;49m\u001b[39m(?P<\u001b[39;49m\u001b[39m%s\u001b[39;49;00m\u001b[39m>\u001b[39;49m\u001b[39m%s\u001b[39;49;00m\u001b[39m)\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39m%\u001b[39;49m pair \u001b[39mfor\u001b[39;00m pair \u001b[39min\u001b[39;00m token_patterns)\n\u001b[0;32m     20\u001b[0m \u001b[39m#print(\"regex_pattern\", regex_pattern)\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \n\u001b[0;32m     22\u001b[0m \u001b[39m# Tokenize the input string using the regex pattern\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[39m# Tokenize the input string using the regex pattern\u001b[39;00m\n\u001b[0;32m     24\u001b[0m tokens \u001b[39m=\u001b[39m []\n",
      "\u001b[1;31mTypeError\u001b[0m: not enough arguments for format string"
     ]
    }
   ],
   "source": [
    "from reg_tokenizer import extract_tokens_pairs\n",
    "\n",
    "input_code = '''\n",
    "def add_numbers(a, b):\n",
    "    result = a + b\n",
    "    return result\n",
    "\n",
    "x = 5\n",
    "y = 10\n",
    "z = add_numbers(x, y)\n",
    "print(z)\n",
    "'''\n",
    "\n",
    "tokens = extract_tokens_pairs(input_code)\n",
    "\n",
    "for token in tokens:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7185d61c927ddfb37d1dd8c83ef96f8f112620be1468d632fb729d0423a9e939"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
